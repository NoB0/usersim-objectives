{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "This notebook contains the code to reproduce the experiments presented in the paper.\n",
    "For details about the methodology and the datasets used, please refer to the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "\n",
    "ParticipantTransitionProbs = Dict[str, Dict[str, float]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome predictor\n",
    "\n",
    "The outcome predictor is defined as follows:\n",
    "\n",
    "$$\\hat{o} = \\frac{1}{1 + \\exp(-h(L, a^t_u, a^t_{CA}, p, i))}$$\n",
    "\n",
    "where $L$ is the length of the dialogue, $a^t_u$ and $a^t_{CA}$ are the actions of the user and the conversational agent at time $t$, $p$ is the patience, and $i$ is the inclination towards goal completion. The function $h$ is defined as follows:\n",
    "\n",
    "$$h(L, a^t_u, a^t_{CA}, p, i) = w_1 * \\frac{p}{L} + w_2 * \\tanh(i) * \\mathbb{1}(a^t_u = \\text{F}) + w_3 * \\mathbb{1}(a^t_{CA} = \\text{A})$$\n",
    "\n",
    "where $w_1$, $w_2$, and $w_3$ are the weights of the features and $\\mathbb{1}$ is the indicator function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dialogue_outcome(\n",
    "    patience: float,\n",
    "    inclination: float,\n",
    "    dialogue: List[str],\n",
    "    weights: List[float] = [1.0, 1.0, 0.5],\n",
    ") -> int:\n",
    "    \"\"\"Predicts the outcome of a dialogue.\n",
    "\n",
    "    Args:\n",
    "        patience: User's patience.\n",
    "        inclination: User's inclination towards goal completion.\n",
    "        dialogue: Dialogue to predict outcome for.\n",
    "        weights: Weights for the features.\n",
    "\n",
    "    Returns:\n",
    "        Outcome of the dialogue (0: failure, 1: success).\n",
    "    \"\"\"\n",
    "    last_user_action = None\n",
    "    last_agent_action = None\n",
    "\n",
    "    for action in reversed(dialogue):\n",
    "        if last_user_action is not None and last_agent_action is not None:\n",
    "            break\n",
    "\n",
    "        if action.startswith(\"U_\") and last_user_action is None:\n",
    "            last_user_action = 1.0 if \"F\" in action else 0.0\n",
    "        elif action.startswith(\"S_\") and last_agent_action is None:\n",
    "            last_agent_action = 1.0 if \"A\" in action else 0.0\n",
    "\n",
    "    if last_user_action is None:\n",
    "        last_user_action = 0.0\n",
    "    if last_agent_action is None:\n",
    "        last_agent_action = 0.0\n",
    "\n",
    "    features = [\n",
    "        patience / len(dialogue),\n",
    "        np.tanh(inclination) * last_user_action,\n",
    "        last_agent_action,\n",
    "    ]\n",
    "    h = sum([w * f for w, f in zip(weights, features)])\n",
    "    outcome_prob = 1 / (1 + np.exp(-h))\n",
    "    return 1 if outcome_prob >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User simulators and conversational agents\n",
    "\n",
    "From the annotated dialogues, we can extract the transition probabilities for the user simulators and conversational agents. The table summarizes the different user simulators and conversational agents.\n",
    "\n",
    "| Dataset     | User simulator | Conversational agent |\n",
    "| ----------- | -------------- | -------------------- |\n",
    "| DSTC1       | U1             | A1                   |\n",
    "| DSTC2       | U2             | A2                   |\n",
    "| ODE         | U3             | A3                   |\n",
    "| SCS         | U4             | A4                   |\n",
    "| MG-ShopDial | U5             | A5                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        patience: float,\n",
    "        inclination: float,\n",
    "        transition_probabilities: ParticipantTransitionProbs = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes a user simulator.\n",
    "\n",
    "        Args:\n",
    "            name: Name of the user simulator.\n",
    "            patience: User's patience.\n",
    "            inclination: User's inclination towards goal completion.\n",
    "            transition_probabilities: Transition probabilities. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.patience = patience\n",
    "        self.inclination = inclination\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "\n",
    "    def add_historical_dialogues(self, dialogues: List[List[str]]) -> None:\n",
    "        \"\"\"Adds historical dialogues.\n",
    "\n",
    "        Args:\n",
    "            dialogues: List of dialogues.\n",
    "        \"\"\"\n",
    "        self.historical_dialogues = dialogues\n",
    "        self.historical_outcomes = [\n",
    "            predict_dialogue_outcome(self.patience, self.inclination, dialogue)\n",
    "            for dialogue in dialogues\n",
    "        ]\n",
    "\n",
    "    def get_user_actions(self) -> List[str]:\n",
    "        \"\"\"Returns the list of possible user actions.\"\"\"\n",
    "        user_actions = set()\n",
    "        for a_action in self.transition_probabilities.keys():\n",
    "            for u_action in self.transition_probabilities[a_action].keys():\n",
    "                user_actions.add(u_action)\n",
    "        return list(user_actions)\n",
    "\n",
    "    def get_agent_actions(self) -> List[str]:\n",
    "        \"\"\"Returns the list of possible agent actions.\"\"\"\n",
    "        return list(self.transition_probabilities.keys()) + [\"End\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dialogues(utterances: pd.DataFrame) -> List[List[str]]:\n",
    "    \"\"\"Preprocesses utterances to get dialogues.\n",
    "\n",
    "    Args:\n",
    "        utterances: All utterances in dataset.\n",
    "\n",
    "    Returns:\n",
    "        List of dialogues, each dialogue is a list of utterances.\n",
    "    \"\"\"\n",
    "    dialogues = []\n",
    "    case = 0\n",
    "    dialogue = []\n",
    "\n",
    "    for _, utterance in utterances.iterrows():\n",
    "        actions = np.unique(\n",
    "            [a[0] for a in utterance[\"new\"].split(\"+\")]\n",
    "        ).tolist()\n",
    "        if utterance[\"case ID\"] != case:\n",
    "            dialogues.append(dialogue)\n",
    "            dialogue = []\n",
    "            case = utterance[\"case ID\"]\n",
    "        elif \"Hello\" not in utterance[\"new\"] and \"Bye\" not in utterance[\"new\"]:\n",
    "            if len(dialogue) > 0 and dialogue[-1].startswith(\n",
    "                f\"{utterance['resource']}_\"\n",
    "            ):\n",
    "                prev_actions = [a[-1] for a in dialogue.pop(-1).split(\"+\")]\n",
    "                actions = prev_actions + actions\n",
    "\n",
    "            dialogue.append(\n",
    "                \"+\".join(\n",
    "                    [\n",
    "                        f\"{utterance['resource']}_{action[0]}\"\n",
    "                        for action in np.unique(actions)\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    dialogues = list(filter(None, dialogues))\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_probabilities(dialogues: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"Get transition probabilities for a list of dialogues.\n",
    "\n",
    "    Args:\n",
    "        dialogues: Dialogues where each dialogue is a string of actions.\n",
    "\n",
    "    Returns:\n",
    "        Transition probabilities for each action in the dialogues.\n",
    "    \"\"\"\n",
    "    transitions = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        for i in range(len(dialogue) - 1):\n",
    "            current_action = dialogue[i]\n",
    "            next_action = dialogue[i + 1]\n",
    "            if i == 0:\n",
    "                transitions[\"Start\"][current_action] += 1\n",
    "\n",
    "            transitions[current_action][next_action] += 1\n",
    "\n",
    "        transitions[dialogue[-1]][\"End\"] += 1\n",
    "\n",
    "    probabilities = {}\n",
    "    for action in transitions.keys():\n",
    "        total = sum(transitions[action].values())\n",
    "        if total > 0:\n",
    "            probabilities[action] = {\n",
    "                next_action: count / total\n",
    "                for next_action, count in transitions[action].items()\n",
    "            }\n",
    "        else:\n",
    "            probabilities[action] = {}\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def get_participants_transition_probs(\n",
    "    transition_probs: Dict[str, float]\n",
    ") -> Tuple[ParticipantTransitionProbs, ParticipantTransitionProbs]:\n",
    "    \"\"\"Gets the transitions probabilities for each participant.\n",
    "\n",
    "    Args:\n",
    "        transition_probs: Transition probabilities for all actions.\n",
    "\n",
    "    Returns:\n",
    "        Transition probabilities for each participant.\n",
    "    \"\"\"\n",
    "    user_transition_probs = {}\n",
    "    agent_transition_probs = {}\n",
    "    for state, transition in transition_probs.items():\n",
    "        if state.startswith(\"U_\"):\n",
    "            agent_transition_probs[state] = transition\n",
    "        elif state.startswith(\"S_\"):\n",
    "            user_transition_probs[state] = transition\n",
    "\n",
    "    return user_transition_probs, agent_transition_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_SIMULATORS = {}\n",
    "CONVERSATIONAL_AGENTS = {}\n",
    "\n",
    "datasets = [\n",
    "    (\n",
    "        \"U1\",\n",
    "        -0.9,\n",
    "        -0.9,\n",
    "        \"A1\",\n",
    "        \"data/annotated_datasets/1_dstc1_updated.csv\",\n",
    "    ),  # Impatient and critical user\n",
    "    (\n",
    "        \"U2\",\n",
    "        0.9,\n",
    "        -0.9,\n",
    "        \"A2\",\n",
    "        \"data/annotated_datasets/2_dstc2_updated.csv\",\n",
    "    ),  # Patient and critical user\n",
    "    (\n",
    "        \"U3\",\n",
    "        -0.9,\n",
    "        0.9,\n",
    "        \"A3\",\n",
    "        \"data/annotated_datasets/5_ode_updated.csv\",\n",
    "    ),  # Impatient and cooperative user\n",
    "    (\n",
    "        \"U4\",\n",
    "        0.9,\n",
    "        0.9,\n",
    "        \"A4\",\n",
    "        \"data/annotated_datasets/4_scs_updated.csv\",\n",
    "    ),  # Patient and cooperative user\n",
    "    (\n",
    "        \"U5\",\n",
    "        1e-5,\n",
    "        1e-5,\n",
    "        \"A5\",\n",
    "        \"data/annotated_datasets/6_mgshopdial_updated.csv\",\n",
    "    ),  # Neutral user\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = {}\n",
    "\n",
    "for user_sim_name, patience, inclination, agent, path in datasets:\n",
    "    print(f\"Processing {path}\")\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.dropna(subset=[\"new\"])\n",
    "    dialogues = preprocess_dialogues(data)\n",
    "\n",
    "    # Compute statistics on the dialogues: avg. # utterance and std dev\n",
    "    num_utterances = [len(dialogue) for dialogue in dialogues]\n",
    "    data_stats[agent] = {\n",
    "        \"# dialogues\": len(dialogues),\n",
    "        \"Avg. # utterances\": mean(num_utterances),\n",
    "        \"Std. dev. # utterances\": stdev(num_utterances),\n",
    "    }\n",
    "\n",
    "    transition_probabilities = get_transition_probabilities(dialogues)\n",
    "    user_transition_probs, agent_transition_probs = (\n",
    "        get_participants_transition_probs(transition_probabilities)\n",
    "    )\n",
    "\n",
    "    population = UserSimulator(\n",
    "        user_sim_name, patience, inclination, user_transition_probs\n",
    "    )\n",
    "    population.add_historical_dialogues(dialogues)\n",
    "    USER_SIMULATORS[user_sim_name] = population\n",
    "\n",
    "    CONVERSATIONAL_AGENTS[agent] = {\n",
    "        \"transition_probabilities\": agent_transition_probs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialogues statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_stats).transpose().style.format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    data,\n",
    "    dialogues,\n",
    "    num_utterances,\n",
    "    transition_probabilities,\n",
    "    user_transition_probs,\n",
    "    agent_transition_probs,\n",
    "    data_stats,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of synthetic dialogues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_action(\n",
    "    current_action: str, transition_probs: ParticipantTransitionProbs\n",
    ") -> str:\n",
    "    \"\"\"Samples the next action based on transition probabilities.\n",
    "\n",
    "    Args:\n",
    "        current_action: Current action.\n",
    "        transition_probs: Transition probabilities.\n",
    "\n",
    "    Returns:\n",
    "        Next action.\n",
    "    \"\"\"\n",
    "    next_actions = list(transition_probs[current_action].keys())\n",
    "    probabilities = list(transition_probs[current_action].values())\n",
    "    sampled_action = np.random.choice(next_actions, p=probabilities)\n",
    "    return sampled_action\n",
    "\n",
    "\n",
    "def sample_dialogue(\n",
    "    agent_transition_probs: ParticipantTransitionProbs,\n",
    "    user_transition_probs: ParticipantTransitionProbs,\n",
    ") -> List[str]:\n",
    "    \"\"\"Samples a dialogue.\n",
    "\n",
    "    Args:\n",
    "        agent_transition_probs: Transition probabilities for the agent.\n",
    "        user_transition_probs: Transition probabilities for the user.\n",
    "\n",
    "    Returns:\n",
    "        Dialogue as list of actions.\n",
    "    \"\"\"\n",
    "    dialogue = []\n",
    "    is_finished = False\n",
    "\n",
    "    current_action = random.choice(\n",
    "        list(agent_transition_probs.keys())\n",
    "        + list(user_transition_probs.keys())\n",
    "    )\n",
    "    dialogue.append(current_action)\n",
    "    while not is_finished:\n",
    "        try:\n",
    "            if current_action.startswith(\"U_\"):\n",
    "                current_action = sample_next_action(\n",
    "                    current_action, agent_transition_probs\n",
    "                )\n",
    "            else:\n",
    "                current_action = sample_next_action(\n",
    "                    current_action, user_transition_probs\n",
    "                )\n",
    "            if current_action == \"End\":\n",
    "                is_finished = True\n",
    "                break\n",
    "            dialogue.append(current_action)\n",
    "        except KeyError:\n",
    "            current_action = current_action.split(\"+\")[-1]\n",
    "\n",
    "    return dialogue\n",
    "\n",
    "\n",
    "def sample_dialogues(\n",
    "    agent_transition_probs: ParticipantTransitionProbs,\n",
    "    user_transition_probs: ParticipantTransitionProbs,\n",
    "    num_dialogues: int,\n",
    "    patience: float,\n",
    "    inclination: float,\n",
    ") -> List[Tuple[List[str], bool]]:\n",
    "    \"\"\"Samples dialogues.\n",
    "\n",
    "    Args:\n",
    "        agent_transition_probs: Transition probabilities for the agent.\n",
    "        user_transition_probs: Transition probabilities for the user.\n",
    "        num_dialogues: Number of dialogues to sample.\n",
    "        patience: User's patience.\n",
    "        inclination: User's inclination towards goal completion.\n",
    "\n",
    "    Returns:\n",
    "        Dialogues with success status.\n",
    "    \"\"\"\n",
    "    dialogues = []\n",
    "    for _ in range(num_dialogues):\n",
    "        dialogue = sample_dialogue(\n",
    "            agent_transition_probs, user_transition_probs\n",
    "        )\n",
    "\n",
    "        success = predict_dialogue_outcome(patience, inclination, dialogue)\n",
    "        dialogues.append((dialogue, success))\n",
    "\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "This part contains the methods to compute the metrics associated to the training and evaluation objectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from rouge_score import rouge_scorer\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We choose to use Jensen-Shannon divergence (JSD) and ROUGE-L as metrics to assess the similarity between the user population and simulated user populations. These allow us to make an assessment at the utterance- and dialogue-level respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jsd(\n",
    "    user_policy: ParticipantTransitionProbs,\n",
    "    simulated_user_policy: ParticipantTransitionProbs,\n",
    ") -> float:\n",
    "    \"\"\"Computes Jensen-Shannon divergence between user and simulated user\n",
    "    policies.\n",
    "\n",
    "    It computes the Jensen-Shannon divergence between the transition\n",
    "    probabilities for each state and then averages them. Epsilon is added to\n",
    "    avoid division by zero.\n",
    "\n",
    "    Args:\n",
    "        user_policy: User policy.\n",
    "        simulated_user_policy: Simulated user policy.\n",
    "\n",
    "    Returns:\n",
    "        Jensen-Shannon divergence.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-9\n",
    "    total_jsd = 0.0\n",
    "    for state, transitions_probabilities in user_policy.items():\n",
    "        # Add epsilon to avoid division by zero\n",
    "        simulated_user_policy[state] = {\n",
    "            k: simulated_user_policy.get(state, {}).get(k, epsilon)\n",
    "            for k in transitions_probabilities.keys()\n",
    "        }\n",
    "\n",
    "        probabilities = np.array(list(transitions_probabilities.values()))\n",
    "        simulated_probabilities = np.array(\n",
    "            list(simulated_user_policy[state].values())\n",
    "        )\n",
    "\n",
    "        total_jsd += distance.jensenshannon(\n",
    "            probabilities, simulated_probabilities, base=2\n",
    "        )\n",
    "    return total_jsd / len(user_policy.keys())\n",
    "\n",
    "\n",
    "def compute_rouge_score(\n",
    "    historical_dialogues: List[List[str]], simulated_dialogues: List[List[str]]\n",
    ") -> float:\n",
    "    \"\"\"Computes ROUGE-L score between historical and simulated dialogues.\n",
    "\n",
    "    It computes the average ROUGE-L score between all pairs of historical and\n",
    "    simulated dialogues.\n",
    "\n",
    "    Args:\n",
    "        historical_dialogues: Historical dialogues.\n",
    "        simulated_dialogues: Simulated dialogues.\n",
    "\n",
    "    Returns:\n",
    "        ROUGE-L score.\n",
    "    \"\"\"\n",
    "    historical_dialogues = [\" \".join(d) for d in historical_dialogues]\n",
    "    simulated_dialogues = [\" \".join(d) for d in simulated_dialogues]\n",
    "    total_score = 0.0\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"])\n",
    "    pairs = list(product(historical_dialogues, simulated_dialogues))\n",
    "    for h, s in pairs:\n",
    "        total_score += scorer.score(h, s)[\"rougeL\"].fmeasure\n",
    "    return total_score / len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We use the success rate as the performance metric to evaluate the conversational agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_success_rate(successes: List[int]) -> float:\n",
    "    \"\"\"Computes success rate.\n",
    "\n",
    "    Args:\n",
    "        successes: Successes.\n",
    "\n",
    "    Returns:\n",
    "        Success rate.\n",
    "    \"\"\"\n",
    "    return sum(successes) / len(successes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross-validation\n",
    "\n",
    "In this part, we perform a leave-out-one out experiment to answer the following questions: is the optimal user simulator for training also the best for evaluation, and vice versa?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [\n",
    "    (\"U1\", \"A1\"),\n",
    "    (\"U2\", \"A2\"),\n",
    "    (\"U3\", \"A3\"),\n",
    "    (\"U4\", \"A4\"),\n",
    "    (\"U5\", \"A5\"),\n",
    "]\n",
    "num_synthetic_dialogues = 500\n",
    "\n",
    "results = defaultdict(dict)\n",
    "\n",
    "for user_pop, agent in references:\n",
    "    print(f\"Reference {agent}\")\n",
    "    user_population = USER_SIMULATORS[user_pop]\n",
    "    if user_pop == \"U3\":\n",
    "        historical_success_rate = 0.92\n",
    "    else:\n",
    "        historical_success_rate = compute_success_rate(\n",
    "            user_population.historical_outcomes\n",
    "        )\n",
    "\n",
    "    for _, user_simulator in USER_SIMULATORS.items():\n",
    "        if user_pop == user_simulator.name:\n",
    "            continue\n",
    "\n",
    "        print(f\"{time.ctime()} - User simulator: {user_simulator.name}\")\n",
    "\n",
    "        # Generate synthetic dialogues\n",
    "        synthetic_dialogues_data = sample_dialogues(\n",
    "            CONVERSATIONAL_AGENTS[agent][\"transition_probabilities\"],\n",
    "            user_simulator.transition_probabilities,\n",
    "            num_synthetic_dialogues,\n",
    "            user_simulator.patience,\n",
    "            user_simulator.inclination,\n",
    "        )\n",
    "\n",
    "        simulated_dialogues = []\n",
    "        simulated_dialogues_success = []\n",
    "        for dialogue, success in synthetic_dialogues_data:\n",
    "            simulated_dialogues.append(dialogue)\n",
    "            simulated_dialogues_success.append(success)\n",
    "\n",
    "        # Compute ROUGE-L score\n",
    "        rouge_l_score = compute_rouge_score(\n",
    "            user_population.historical_dialogues,\n",
    "            simulated_dialogues,\n",
    "        )\n",
    "\n",
    "        # Compute success rate\n",
    "        success_rate = compute_success_rate(simulated_dialogues_success)\n",
    "\n",
    "        # Absolute difference success rate\n",
    "        abs_diff_success_rate = abs(success_rate - historical_success_rate)\n",
    "\n",
    "        results[agent][user_simulator.name] = {\n",
    "            \"ROUGE-L\": rouge_l_score,\n",
    "            \"Success rate\": success_rate,\n",
    "            \"Abs. diff. success rate\": abs_diff_success_rate,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for agent, d in results.items():\n",
    "    for simulated_user, metrics in d.items():\n",
    "        rows.append(\n",
    "            (\n",
    "                agent,\n",
    "                simulated_user,\n",
    "                *(value for _, value in metrics.items()),\n",
    "            )\n",
    "        )\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"Reference\",\n",
    "        \"User Simulator\",\n",
    "        \"ROUGE-L\",\n",
    "        \"Success rate\",\n",
    "        \"Abs. diff. success rate\",\n",
    "    ],\n",
    ")\n",
    "summary.set_index([\"Reference\", \"User Simulator\"], inplace=True)\n",
    "\n",
    "summary.style.format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jensen-Shannon divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_results = defaultdict(dict)\n",
    "\n",
    "for user1, user2 in product(USER_SIMULATORS.keys(), repeat=2):\n",
    "    if user1 != user2:\n",
    "        user_policy1 = USER_SIMULATORS[user1].transition_probabilities\n",
    "        user_policy2 = USER_SIMULATORS[user2].transition_probabilities\n",
    "        jsd = compute_jsd(user_policy1, user_policy2)\n",
    "        jsd_results[user1][user2] = jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(jsd_results).sort_index().style.format(precision=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigir24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
