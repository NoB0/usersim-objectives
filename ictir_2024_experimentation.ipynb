{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical analysis ICTIR '24\n",
    "\n",
    "This notebook contains the code to reproduce the experiments presented in the paper.\n",
    "\n",
    "Note that we focus on the dialogue policy and do not consider the other modules such as NLU and NLG of the conversational agent. The interaction model QRFA is used to build the dialogue policies for both the user simulators and the conversational agent. The user's actions are query and feedback, while the agent's actions are request and answer. Additionally, there is an action to finish the conversation that is shared by both.\n",
    "\n",
    "## Data\n",
    "\n",
    "For the experiments, we use the annotated datasets released along with the QRFA model. This choice is motivated by the fact that these datasets comprise different user behaviors to complete an information seeking task. Therefore, we assume a certain level of realism in the user simulators and conversational agents built using these datasets. The table below introduce the datasets.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "For each datasets, we build a user simulator and a conversational agent.\n",
    "Based one the idea of leave-one-out cross-validation, we study the implication relationships between the objectives of training and evaluation by considering the user population and agent associated to a dataset as the reference and the other user populations as simulated user populations. For each reference pair, we execute the following steps:\n",
    "\n",
    "1. Get transition probabilities from the reference user population and conversational agent.\n",
    "2. Train a success predicator for each simulated user population.\n",
    "3. Generate synthetic dialogues between the reference agent and the simulated user populations. Each dialogue is given a success score using scoring predictors.\n",
    "4. Compute metrics associated to the objectives of training and evaluation.\n",
    "5. Identify the best user simulator for training and evaluation based on the computed metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "\n",
    "ParticipantTransitionProbs = Dict[str, Dict[str, float]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome predictor\n",
    "\n",
    "The outcome predictor is defined as follows:\n",
    "\n",
    "$$\\hat{o} = \\frac{1}{1 + \\exp(-h(L, a^t_u, a^t_{CA}, p, i))}$$\n",
    "\n",
    "where $L$ is the length of the dialogue, $a^t_u$ and $a^t_{CA}$ are the actions of the user and the conversational agent at time $t$, $p$ is the patience, and $i$ is the inclination towards goal completion. The function $h$ is defined as follows:\n",
    "\n",
    "$$h(L, a^t_u, a^t_{CA}, p, i) = w_1 * \\frac{p}{L} + w_2 * \\tanh(i) * \\mathbb{1}(a^t_u = \\text{F}) + w_3 * \\mathbb{1}(a^t_{CA} = \\text{A})$$\n",
    "\n",
    "where $w_1$, $w_2$, $w_3$, and $w_4$ are the weights of the features and $\\mathbb{1}$ is the indicator function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dialogue_outcome(\n",
    "    patience: float,\n",
    "    inclination: float,\n",
    "    dialogue: List[str],\n",
    "    weights: List[float] = [1.0, 1.0, 0.5],\n",
    ") -> int:\n",
    "    \"\"\"Predicts the outcome of a dialogue.\n",
    "\n",
    "    Args:\n",
    "        patience: User's patience.\n",
    "        inclination: User's inclination towards goal completion.\n",
    "        dialogue: Dialogue to predict outcome for.\n",
    "        weights: Weights for the features.\n",
    "\n",
    "    Returns:\n",
    "        Outcome of the dialogue (0: failure, 1: success).\n",
    "    \"\"\"\n",
    "    last_user_action = None\n",
    "    last_agent_action = None\n",
    "\n",
    "    for action in reversed(dialogue):\n",
    "        if last_user_action is not None and last_agent_action is not None:\n",
    "            break\n",
    "        \n",
    "        if action.startswith(\"U_\") and last_user_action is None:\n",
    "            last_user_action = 1.0 if \"F\" in action else 0.0\n",
    "        elif action.startswith(\"S_\") and last_agent_action is None:\n",
    "            last_agent_action = 1.0 if \"A\" in action else 0.0\n",
    "\n",
    "    if last_user_action is None:\n",
    "        last_user_action = 0.0\n",
    "    if last_agent_action is None:\n",
    "        last_agent_action = 0.0\n",
    "\n",
    "    features = [\n",
    "        patience / len(dialogue),\n",
    "        np.tanh(inclination) * last_user_action,\n",
    "        last_agent_action,\n",
    "    ]\n",
    "    h = sum([w * f for w, f in zip(weights, features)])\n",
    "    outcome_prob = 1 / (1 + np.exp(-h))\n",
    "    return 1 if outcome_prob >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User populations and conversational agents\n",
    "\n",
    "From the annotated dialogues, we can extract the transition probabilities for the user populations and conversational agents. The table summarizes the different user populations and conversational agents.\n",
    "\n",
    "| Dataset | User populations | Conversational agents |\n",
    "| ------- | ---------------- | --------------------- |\n",
    "| DSTC1   | U1               | A1                    |\n",
    "| DSTC2   | U2               | A2                    |\n",
    "| ODE     | U3               | A3                    |\n",
    "| SCS     | U4               | A4                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPopulation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        patience: float,\n",
    "        inclination: float,\n",
    "        transition_probabilities: ParticipantTransitionProbs = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes a user population.\n",
    "\n",
    "        Args:\n",
    "            name: Name of the user population.\n",
    "            patience: User's patience.\n",
    "            inclination: User's inclination towards goal completion.\n",
    "            transition_probabilities: Transition probabilities. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.patience = patience\n",
    "        self.inclination = inclination\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "\n",
    "    def add_historical_dialogues(self, dialogues: List[List[str]]) -> None:\n",
    "        \"\"\"Adds historical dialogues to the user population.\n",
    "\n",
    "        Args:\n",
    "            dialogues: List of dialogues.\n",
    "        \"\"\"\n",
    "        self.historical_dialogues = dialogues\n",
    "        self.historical_outcomes = [predict_dialogue_outcome(self.patience, self.inclination, dialogue) for dialogue in dialogues]\n",
    "\n",
    "    def get_user_actions(self) -> List[str]:\n",
    "        \"\"\"Returns the list of possible user actions.\"\"\"\n",
    "        user_actions = set()\n",
    "        for a_action in self.transition_probabilities.keys():\n",
    "            for u_action in self.transition_probabilities[a_action].keys():\n",
    "                user_actions.add(u_action)\n",
    "        return list(user_actions)\n",
    "\n",
    "    def get_agent_actions(self) -> List[str]:\n",
    "        \"\"\"Returns the list of possible agent actions.\"\"\"\n",
    "        return list(self.transition_probabilities.keys()) + [\"End\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dialogues(utterances: pd.DataFrame) -> List[List[str]]:\n",
    "    \"\"\"Preprocesses utterances to get dialogues.\n",
    "\n",
    "    Args:\n",
    "        utterances: All utterances in dataset.\n",
    "\n",
    "    Returns:\n",
    "        List of dialogues, each dialogue is a list of utterances.\n",
    "    \"\"\"\n",
    "    dialogues = []\n",
    "    case = 0\n",
    "    dialogue = []\n",
    "\n",
    "    for _, utterance in utterances.iterrows():\n",
    "        actions = np.unique(\n",
    "            [a[0] for a in utterance[\"new\"].split(\"+\")]\n",
    "        ).tolist()\n",
    "        if utterance[\"case ID\"] != case:\n",
    "            dialogues.append(dialogue)\n",
    "            dialogue = []\n",
    "            case = utterance[\"case ID\"]\n",
    "        elif \"Hello\" not in utterance[\"new\"] and \"Bye\" not in utterance[\"new\"]:\n",
    "            if len(dialogue) > 0 and dialogue[-1].startswith(\n",
    "                f\"{utterance['resource']}_\"\n",
    "            ):\n",
    "                prev_actions = [a[-1] for a in dialogue.pop(-1).split(\"+\")]\n",
    "                actions = prev_actions + actions\n",
    "\n",
    "            dialogue.append(\n",
    "                \"+\".join(\n",
    "                    [\n",
    "                        f\"{utterance['resource']}_{action[0]}\"\n",
    "                        for action in np.unique(actions)\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    dialogues = list(filter(None, dialogues))\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_probabilities(dialogues: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"Get transition probabilities for a list of dialogues.\n",
    "\n",
    "    Args:\n",
    "        dialogues: Dialogues where each dialogue is a string of actions.\n",
    "\n",
    "    Returns:\n",
    "        Transition probabilities for each action in the dialogues.\n",
    "    \"\"\"\n",
    "    transitions = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        for i in range(len(dialogue) - 1):\n",
    "            current_action = dialogue[i]\n",
    "            next_action = dialogue[i + 1]\n",
    "            if i == 0:\n",
    "                transitions[\"Start\"][current_action] += 1\n",
    "\n",
    "            transitions[current_action][next_action] += 1\n",
    "\n",
    "        transitions[dialogue[-1]][\"End\"] += 1\n",
    "\n",
    "    probabilities = {}\n",
    "    for action in transitions.keys():\n",
    "        total = sum(transitions[action].values())\n",
    "        if total > 0:\n",
    "            probabilities[action] = {\n",
    "                next_action: count / total\n",
    "                for next_action, count in transitions[action].items()\n",
    "            }\n",
    "        else:\n",
    "            probabilities[action] = {}\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def get_participants_transition_probs(\n",
    "    transition_probs: Dict[str, float]\n",
    ") -> Tuple[ParticipantTransitionProbs, ParticipantTransitionProbs]:\n",
    "    \"\"\"Gets the transitions probabilities for each participant.\n",
    "\n",
    "    Args:\n",
    "        transition_probs: Transition probabilities for all actions.\n",
    "\n",
    "    Returns:\n",
    "        Transition probabilities for each participant.\n",
    "    \"\"\"\n",
    "    user_transition_probs = {}\n",
    "    agent_transition_probs = {}\n",
    "    for state, transition in transition_probs.items():\n",
    "        if state.startswith(\"U_\"):\n",
    "            agent_transition_probs[state] = transition\n",
    "        elif state.startswith(\"S_\"):\n",
    "            user_transition_probs[state] = transition\n",
    "\n",
    "    return user_transition_probs, agent_transition_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_POPULATIONS = {}\n",
    "AGENT_POPULATIONS = {}\n",
    "\n",
    "datasets = [\n",
    "    (\"U1\", -0.9, -0.9, \"A1\", \"data/annotated_datasets/1_dstc1_updated.csv\"),      # Impatient and critical user\n",
    "    (\"U2\", 0.9, -0.9, \"A2\", \"data/annotated_datasets/2_dstc2_updated.csv\"),       # Patient and critical user\n",
    "    (\"U3\", -.9, 0.9, \"A3\", \"data/annotated_datasets/5_ode_updated.csv\"),          # Impatient and cooperative user\n",
    "    (\"U4\", .9, .9, \"A4\", \"data/annotated_datasets/4_scs_updated.csv\"),            # Patient and cooperative user\n",
    "    (\"U5\", 1e-5, 1e-5, \"A5\", \"data/annotated_datasets/6_mgshopdial_updated.csv\"), # Neutral user\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/annotated_datasets/1_dstc1_updated.csv\n",
      "Processing data/annotated_datasets/2_dstc2_updated.csv\n",
      "Processing data/annotated_datasets/5_ode_updated.csv\n",
      "Processing data/annotated_datasets/4_scs_updated.csv\n",
      "Processing data/annotated_datasets/6_mgshopdial_updated.csv\n"
     ]
    }
   ],
   "source": [
    "data_stats = {}\n",
    "\n",
    "for user_pop, patience, inclination, agent, path in datasets:\n",
    "    print(f\"Processing {path}\")\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.dropna(subset=[\"new\"])\n",
    "    dialogues = preprocess_dialogues(data)\n",
    "\n",
    "    # Compute statistics on the dialogues: avg. # utterance and std dev\n",
    "    num_utterances = [len(dialogue) for dialogue in dialogues]\n",
    "    data_stats[f\"D({user_pop}, {agent})\"] = {\n",
    "        \"# dialogues\": len(dialogues),\n",
    "        \"Avg. # utterances\": mean(num_utterances),\n",
    "        \"Std. dev. # utterances\": stdev(num_utterances),\n",
    "    }\n",
    "\n",
    "    transition_probabilities = get_transition_probabilities(dialogues)\n",
    "    user_transition_probs, agent_transition_probs = (\n",
    "        get_participants_transition_probs(transition_probabilities)\n",
    "    )\n",
    "\n",
    "    population = UserPopulation(\n",
    "        user_pop, patience, inclination, user_transition_probs\n",
    "    )\n",
    "    population.add_historical_dialogues(dialogues)\n",
    "    USER_POPULATIONS[user_pop] = population\n",
    "\n",
    "    AGENT_POPULATIONS[agent] = {\n",
    "        \"transition_probabilities\": agent_transition_probs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialogues statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_942df\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_942df_level0_col0\" class=\"col_heading level0 col0\" ># dialogues</th>\n",
       "      <th id=\"T_942df_level0_col1\" class=\"col_heading level0 col1\" >Avg. # utterances</th>\n",
       "      <th id=\"T_942df_level0_col2\" class=\"col_heading level0 col2\" >Std. dev. # utterances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_942df_level0_row0\" class=\"row_heading level0 row0\" >D(U1, A1)</th>\n",
       "      <td id=\"T_942df_row0_col0\" class=\"data row0 col0\" >15577.000</td>\n",
       "      <td id=\"T_942df_row0_col1\" class=\"data row0 col1\" >24.217</td>\n",
       "      <td id=\"T_942df_row0_col2\" class=\"data row0 col2\" >22.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_942df_level0_row1\" class=\"row_heading level0 row1\" >D(U2, A2)</th>\n",
       "      <td id=\"T_942df_row1_col0\" class=\"data row1 col0\" >2117.000</td>\n",
       "      <td id=\"T_942df_row1_col1\" class=\"data row1 col1\" >10.171</td>\n",
       "      <td id=\"T_942df_row1_col2\" class=\"data row1 col2\" >4.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_942df_level0_row2\" class=\"row_heading level0 row2\" >D(U3, A3)</th>\n",
       "      <td id=\"T_942df_row2_col0\" class=\"data row2 col0\" >25.000</td>\n",
       "      <td id=\"T_942df_row2_col1\" class=\"data row2 col1\" >15.000</td>\n",
       "      <td id=\"T_942df_row2_col2\" class=\"data row2 col2\" >8.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_942df_level0_row3\" class=\"row_heading level0 row3\" >D(U4, A4)</th>\n",
       "      <td id=\"T_942df_row3_col0\" class=\"data row3 col0\" >38.000</td>\n",
       "      <td id=\"T_942df_row3_col1\" class=\"data row3 col1\" >1.579</td>\n",
       "      <td id=\"T_942df_row3_col2\" class=\"data row3 col2\" >0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_942df_level0_row4\" class=\"row_heading level0 row4\" >D(U5, A5)</th>\n",
       "      <td id=\"T_942df_row4_col0\" class=\"data row4 col0\" >63.000</td>\n",
       "      <td id=\"T_942df_row4_col1\" class=\"data row4 col1\" >20.159</td>\n",
       "      <td id=\"T_942df_row4_col2\" class=\"data row4 col2\" >9.474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12b3f2400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_stats).transpose().style.format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    data,\n",
    "    dialogues,\n",
    "    num_utterances,\n",
    "    transition_probabilities,\n",
    "    user_transition_probs,\n",
    "    agent_transition_probs,\n",
    "    data_stats,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of synthetic dialogues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_action(\n",
    "    current_action: str, transition_probs: ParticipantTransitionProbs\n",
    ") -> str:\n",
    "    \"\"\"Samples the next action based on transition probabilities.\n",
    "\n",
    "    Args:\n",
    "        current_action: Current action.\n",
    "        transition_probs: Transition probabilities.\n",
    "\n",
    "    Returns:\n",
    "        Next action.\n",
    "    \"\"\"\n",
    "    next_actions = list(transition_probs[current_action].keys())\n",
    "    probabilities = list(transition_probs[current_action].values())\n",
    "    sampled_action = np.random.choice(next_actions, p=probabilities)\n",
    "    return sampled_action\n",
    "\n",
    "\n",
    "def sample_dialogue(\n",
    "    agent_transition_probs: ParticipantTransitionProbs,\n",
    "    user_transition_probs: ParticipantTransitionProbs,\n",
    ") -> List[str]:\n",
    "    \"\"\"Samples a dialogue.\n",
    "\n",
    "    Args:\n",
    "        agent_transition_probs: Transition probabilities for the agent.\n",
    "        user_transition_probs: Transition probabilities for the user.\n",
    "\n",
    "    Returns:\n",
    "        Dialogue as list of actions.\n",
    "    \"\"\"\n",
    "    dialogue = []\n",
    "    is_finished = False\n",
    "\n",
    "    current_action = random.choice(\n",
    "        list(agent_transition_probs.keys())\n",
    "        + list(user_transition_probs.keys())\n",
    "    )\n",
    "    dialogue.append(current_action)\n",
    "    while not is_finished:\n",
    "        try:\n",
    "            if current_action.startswith(\"U_\"):\n",
    "                current_action = sample_next_action(\n",
    "                    current_action, agent_transition_probs\n",
    "                )\n",
    "            else:\n",
    "                current_action = sample_next_action(\n",
    "                    current_action, user_transition_probs\n",
    "                )\n",
    "            if current_action == \"End\":\n",
    "                is_finished = True\n",
    "                break\n",
    "            dialogue.append(current_action)\n",
    "        except KeyError:\n",
    "            current_action = current_action.split(\"+\")[-1]\n",
    "\n",
    "    return dialogue\n",
    "\n",
    "\n",
    "def sample_dialogues(\n",
    "    agent_transition_probs: ParticipantTransitionProbs,\n",
    "    user_transition_probs: ParticipantTransitionProbs,\n",
    "    num_dialogues: int,\n",
    "    patience: float,\n",
    "    inclination: float,\n",
    ") -> List[Tuple[List[str], bool]]:\n",
    "    \"\"\"Samples dialogues.\n",
    "\n",
    "    Args:\n",
    "        agent_transition_probs: Transition probabilities for the agent.\n",
    "        user_transition_probs: Transition probabilities for the user.\n",
    "        num_dialogues: Number of dialogues to sample.\n",
    "        patience: User's patience.\n",
    "        inclination: User's inclination towards goal completion.\n",
    "\n",
    "    Returns:\n",
    "        Dialogues with success status.\n",
    "    \"\"\"\n",
    "    dialogues = []\n",
    "    for _ in range(num_dialogues):\n",
    "        dialogue = sample_dialogue(\n",
    "            agent_transition_probs, user_transition_probs\n",
    "        )\n",
    "\n",
    "        success = predict_dialogue_outcome(\n",
    "            patience, inclination, dialogue\n",
    "        )\n",
    "        dialogues.append((dialogue, success))\n",
    "\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "This part contains the methods to compute the metrics associated to the training and evaluation objectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from rouge_score import rouge_scorer\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We choose to use Jensen-Shannon divergence (JSD) and ROUGE-L as metrics to assess the similarity between the user population and simulated user populations. These allow us to make an assessment at the utterance- and dialogue-level respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jsd(\n",
    "    user_policy: ParticipantTransitionProbs,\n",
    "    simulated_user_policy: ParticipantTransitionProbs,\n",
    ") -> float:\n",
    "    \"\"\"Computes Jensen-Shannon divergence between user and simulated user\n",
    "    policies.\n",
    "\n",
    "    It computes the Jensen-Shannon divergence between the transition\n",
    "    probabilities for each state and then averages them. Epsilon is added to\n",
    "    avoid division by zero.\n",
    "\n",
    "    Args:\n",
    "        user_policy: User policy.\n",
    "        simulated_user_policy: Simulated user policy.\n",
    "\n",
    "    Returns:\n",
    "        Jensen-Shannon divergence.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-9\n",
    "    total_jsd = 0.0\n",
    "    for state, transitions_probabilities in user_policy.items():\n",
    "        # Add epsilon to avoid division by zero\n",
    "        simulated_user_policy[state] = {\n",
    "            k: simulated_user_policy.get(state, {}).get(k, epsilon)\n",
    "            for k in transitions_probabilities.keys()\n",
    "        }\n",
    "\n",
    "        probabilities = np.array(list(transitions_probabilities.values()))\n",
    "        simulated_probabilities = np.array(\n",
    "            list(simulated_user_policy[state].values())\n",
    "        )\n",
    "\n",
    "        total_jsd += distance.jensenshannon(\n",
    "            probabilities, simulated_probabilities, base=2\n",
    "        )\n",
    "    return total_jsd / len(user_policy.keys())\n",
    "\n",
    "\n",
    "def compute_rouge_score(\n",
    "    historical_dialogues: List[List[str]], simulated_dialogues: List[List[str]]\n",
    ") -> float:\n",
    "    \"\"\"Computes ROUGE-L score between historical and simulated dialogues.\n",
    "\n",
    "    It computes the average ROUGE-L score between all pairs of historical and\n",
    "    simulated dialogues.\n",
    "\n",
    "    Args:\n",
    "        historical_dialogues: Historical dialogues.\n",
    "        simulated_dialogues: Simulated dialogues.\n",
    "\n",
    "    Returns:\n",
    "        ROUGE-L score.\n",
    "    \"\"\"\n",
    "    historical_dialogues = [\" \".join(d) for d in historical_dialogues]\n",
    "    simulated_dialogues = [\" \".join(d) for d in simulated_dialogues]\n",
    "    total_score = 0.0\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"])\n",
    "    pairs = list(product(historical_dialogues, simulated_dialogues))\n",
    "    for h, s in pairs:\n",
    "        total_score += scorer.score(h, s)[\"rougeL\"].fmeasure\n",
    "    return total_score / len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We use the success rate as the performance metric to evaluate the conversational agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_success_rate(successes: List[int]) -> float:\n",
    "    \"\"\"Computes success rate.\n",
    "\n",
    "    Args:\n",
    "        successes: Successes.\n",
    "\n",
    "    Returns:\n",
    "        Success rate.\n",
    "    \"\"\"\n",
    "    return sum(successes) / len(successes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross-validation\n",
    "\n",
    "In this part, we perform a leave-out-one out experiment to answer the following questions: is the optimal user simulator for training also the best for evaluation, and vice versa?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference - U1, A1\n",
      "Tue Apr  2 18:48:35 2024 - Simulated user population: U2\n",
      "Tue Apr  2 21:54:22 2024 - Simulated user population: U3\n",
      "Wed Apr  3 02:42:55 2024 - Simulated user population: U4\n",
      "Wed Apr  3 08:06:10 2024 - Simulated user population: U5\n",
      "Reference - U2, A2\n",
      "Wed Apr  3 08:58:04 2024 - Simulated user population: U1\n",
      "Wed Apr  3 09:02:37 2024 - Simulated user population: U3\n",
      "Wed Apr  3 09:05:22 2024 - Simulated user population: U4\n",
      "Wed Apr  3 09:05:59 2024 - Simulated user population: U5\n",
      "Reference - U3, A3\n",
      "Wed Apr  3 09:12:12 2024 - Simulated user population: U1\n",
      "Wed Apr  3 09:12:14 2024 - Simulated user population: U2\n",
      "Wed Apr  3 09:12:16 2024 - Simulated user population: U4\n",
      "Wed Apr  3 09:12:17 2024 - Simulated user population: U5\n",
      "Reference - U4, A4\n",
      "Wed Apr  3 09:12:22 2024 - Simulated user population: U1\n",
      "Wed Apr  3 09:12:22 2024 - Simulated user population: U2\n",
      "Wed Apr  3 09:12:22 2024 - Simulated user population: U3\n",
      "Wed Apr  3 09:12:22 2024 - Simulated user population: U5\n",
      "Reference - U5, A5\n",
      "Wed Apr  3 09:12:22 2024 - Simulated user population: U1\n",
      "Wed Apr  3 09:12:36 2024 - Simulated user population: U2\n",
      "Wed Apr  3 09:12:43 2024 - Simulated user population: U3\n",
      "Wed Apr  3 09:12:56 2024 - Simulated user population: U4\n"
     ]
    }
   ],
   "source": [
    "participant_pairs = [(\"U1\", \"A1\"), (\"U2\", \"A2\"), (\"U3\", \"A3\"), (\"U4\", \"A4\"), (\"U5\", \"A5\")]\n",
    "# participant_pairs = [(\"U2\", \"A2\"), (\"U3\", \"A3\"), (\"U4\", \"A4\"), (\"U5\", \"A5\")]\n",
    "num_synthetic_dialogues = 500\n",
    "\n",
    "results = defaultdict(dict)\n",
    "\n",
    "for user_pop, agent in participant_pairs:\n",
    "    print(f\"Reference - {user_pop}, {agent}\")\n",
    "    user_population = USER_POPULATIONS[user_pop]\n",
    "    historical_success_rate = compute_success_rate(\n",
    "        user_population.historical_outcomes\n",
    "    )\n",
    "    for _, simulated_user_population in USER_POPULATIONS.items():\n",
    "        if user_pop == simulated_user_population.name:\n",
    "            continue\n",
    "\n",
    "        print(f\"{time.ctime()} - Simulated user population: {simulated_user_population.name}\")\n",
    "        \n",
    "        # Generate synthetic dialogues\n",
    "        synthetic_dialogues_data = sample_dialogues(\n",
    "            AGENT_POPULATIONS[agent][\"transition_probabilities\"],\n",
    "            simulated_user_population.transition_probabilities,\n",
    "            num_synthetic_dialogues,\n",
    "            simulated_user_population.patience,\n",
    "            simulated_user_population.inclination,\n",
    "        )\n",
    "\n",
    "        simulated_dialogues = []\n",
    "        simulated_dialogues_success = []\n",
    "        for dialogue, success in synthetic_dialogues_data:\n",
    "            simulated_dialogues.append(dialogue)\n",
    "            simulated_dialogues_success.append(success)\n",
    "\n",
    "        # Compute ROUGE-L score\n",
    "        rouge_l_score = compute_rouge_score(\n",
    "            user_population.historical_dialogues,\n",
    "            simulated_dialogues,\n",
    "        )\n",
    "\n",
    "        # Compute success rate\n",
    "        success_rate = compute_success_rate(simulated_dialogues_success)\n",
    "\n",
    "        # Absolute difference success rate\n",
    "        abs_diff_success_rate = abs(\n",
    "            success_rate\n",
    "            - historical_success_rate\n",
    "        )\n",
    "\n",
    "        results[f\"{user_pop}, {agent}\"][simulated_user_population.name] = {\n",
    "            \"ROUGE-L\": rouge_l_score,\n",
    "            \"Success rate\": success_rate,\n",
    "            \"Abs. diff. success rate\": abs_diff_success_rate,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ab5ae\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ab5ae_level0_col0\" class=\"col_heading level0 col0\" >ROUGE-L</th>\n",
       "      <th id=\"T_ab5ae_level0_col1\" class=\"col_heading level0 col1\" >Success rate</th>\n",
       "      <th id=\"T_ab5ae_level0_col2\" class=\"col_heading level0 col2\" >Abs. diff. success rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Reference</th>\n",
       "      <th class=\"index_name level1\" >Simulated user pop.</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">U1, A1</th>\n",
       "      <th id=\"T_ab5ae_level1_row0\" class=\"row_heading level1 row0\" >U2</th>\n",
       "      <td id=\"T_ab5ae_row0_col0\" class=\"data row0 col0\" >0.493</td>\n",
       "      <td id=\"T_ab5ae_row0_col1\" class=\"data row0 col1\" >0.834</td>\n",
       "      <td id=\"T_ab5ae_row0_col2\" class=\"data row0 col2\" >0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row1\" class=\"row_heading level1 row1\" >U3</th>\n",
       "      <td id=\"T_ab5ae_row1_col0\" class=\"data row1 col0\" >0.495</td>\n",
       "      <td id=\"T_ab5ae_row1_col1\" class=\"data row1 col1\" >0.598</td>\n",
       "      <td id=\"T_ab5ae_row1_col2\" class=\"data row1 col2\" >0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row2\" class=\"row_heading level1 row2\" >U4</th>\n",
       "      <td id=\"T_ab5ae_row2_col0\" class=\"data row2 col0\" >0.429</td>\n",
       "      <td id=\"T_ab5ae_row2_col1\" class=\"data row2 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row2_col2\" class=\"data row2 col2\" >0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row3\" class=\"row_heading level1 row3\" >U5</th>\n",
       "      <td id=\"T_ab5ae_row3_col0\" class=\"data row3 col0\" >0.492</td>\n",
       "      <td id=\"T_ab5ae_row3_col1\" class=\"data row3 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row3_col2\" class=\"data row3 col2\" >0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">U2, A2</th>\n",
       "      <th id=\"T_ab5ae_level1_row4\" class=\"row_heading level1 row4\" >U1</th>\n",
       "      <td id=\"T_ab5ae_row4_col0\" class=\"data row4 col0\" >0.456</td>\n",
       "      <td id=\"T_ab5ae_row4_col1\" class=\"data row4 col1\" >0.692</td>\n",
       "      <td id=\"T_ab5ae_row4_col2\" class=\"data row4 col2\" >0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row5\" class=\"row_heading level1 row5\" >U3</th>\n",
       "      <td id=\"T_ab5ae_row5_col0\" class=\"data row5 col0\" >0.520</td>\n",
       "      <td id=\"T_ab5ae_row5_col1\" class=\"data row5 col1\" >0.968</td>\n",
       "      <td id=\"T_ab5ae_row5_col2\" class=\"data row5 col2\" >0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row6\" class=\"row_heading level1 row6\" >U4</th>\n",
       "      <td id=\"T_ab5ae_row6_col0\" class=\"data row6 col0\" >0.457</td>\n",
       "      <td id=\"T_ab5ae_row6_col1\" class=\"data row6 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row6_col2\" class=\"data row6 col2\" >0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row7\" class=\"row_heading level1 row7\" >U5</th>\n",
       "      <td id=\"T_ab5ae_row7_col0\" class=\"data row7 col0\" >0.405</td>\n",
       "      <td id=\"T_ab5ae_row7_col1\" class=\"data row7 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row7_col2\" class=\"data row7 col2\" >0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"4\">U3, A3</th>\n",
       "      <th id=\"T_ab5ae_level1_row8\" class=\"row_heading level1 row8\" >U1</th>\n",
       "      <td id=\"T_ab5ae_row8_col0\" class=\"data row8 col0\" >0.525</td>\n",
       "      <td id=\"T_ab5ae_row8_col1\" class=\"data row8 col1\" >0.142</td>\n",
       "      <td id=\"T_ab5ae_row8_col2\" class=\"data row8 col2\" >0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row9\" class=\"row_heading level1 row9\" >U2</th>\n",
       "      <td id=\"T_ab5ae_row9_col0\" class=\"data row9 col0\" >0.500</td>\n",
       "      <td id=\"T_ab5ae_row9_col1\" class=\"data row9 col1\" >0.754</td>\n",
       "      <td id=\"T_ab5ae_row9_col2\" class=\"data row9 col2\" >0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row10\" class=\"row_heading level1 row10\" >U4</th>\n",
       "      <td id=\"T_ab5ae_row10_col0\" class=\"data row10 col0\" >0.414</td>\n",
       "      <td id=\"T_ab5ae_row10_col1\" class=\"data row10 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row10_col2\" class=\"data row10 col2\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row11\" class=\"row_heading level1 row11\" >U5</th>\n",
       "      <td id=\"T_ab5ae_row11_col0\" class=\"data row11 col0\" >0.458</td>\n",
       "      <td id=\"T_ab5ae_row11_col1\" class=\"data row11 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row11_col2\" class=\"data row11 col2\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level0_row12\" class=\"row_heading level0 row12\" rowspan=\"4\">U4, A4</th>\n",
       "      <th id=\"T_ab5ae_level1_row12\" class=\"row_heading level1 row12\" >U1</th>\n",
       "      <td id=\"T_ab5ae_row12_col0\" class=\"data row12 col0\" >0.513</td>\n",
       "      <td id=\"T_ab5ae_row12_col1\" class=\"data row12 col1\" >0.334</td>\n",
       "      <td id=\"T_ab5ae_row12_col2\" class=\"data row12 col2\" >0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row13\" class=\"row_heading level1 row13\" >U2</th>\n",
       "      <td id=\"T_ab5ae_row13_col0\" class=\"data row13 col0\" >0.508</td>\n",
       "      <td id=\"T_ab5ae_row13_col1\" class=\"data row13 col1\" >0.966</td>\n",
       "      <td id=\"T_ab5ae_row13_col2\" class=\"data row13 col2\" >0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row14\" class=\"row_heading level1 row14\" >U3</th>\n",
       "      <td id=\"T_ab5ae_row14_col0\" class=\"data row14 col0\" >0.462</td>\n",
       "      <td id=\"T_ab5ae_row14_col1\" class=\"data row14 col1\" >0.322</td>\n",
       "      <td id=\"T_ab5ae_row14_col2\" class=\"data row14 col2\" >0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row15\" class=\"row_heading level1 row15\" >U5</th>\n",
       "      <td id=\"T_ab5ae_row15_col0\" class=\"data row15 col0\" >0.503</td>\n",
       "      <td id=\"T_ab5ae_row15_col1\" class=\"data row15 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row15_col2\" class=\"data row15 col2\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"4\">U5, A5</th>\n",
       "      <th id=\"T_ab5ae_level1_row16\" class=\"row_heading level1 row16\" >U1</th>\n",
       "      <td id=\"T_ab5ae_row16_col0\" class=\"data row16 col0\" >0.550</td>\n",
       "      <td id=\"T_ab5ae_row16_col1\" class=\"data row16 col1\" >0.688</td>\n",
       "      <td id=\"T_ab5ae_row16_col2\" class=\"data row16 col2\" >0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row17\" class=\"row_heading level1 row17\" >U2</th>\n",
       "      <td id=\"T_ab5ae_row17_col0\" class=\"data row17 col0\" >0.454</td>\n",
       "      <td id=\"T_ab5ae_row17_col1\" class=\"data row17 col1\" >0.932</td>\n",
       "      <td id=\"T_ab5ae_row17_col2\" class=\"data row17 col2\" >0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row18\" class=\"row_heading level1 row18\" >U3</th>\n",
       "      <td id=\"T_ab5ae_row18_col0\" class=\"data row18 col0\" >0.515</td>\n",
       "      <td id=\"T_ab5ae_row18_col1\" class=\"data row18 col1\" >0.836</td>\n",
       "      <td id=\"T_ab5ae_row18_col2\" class=\"data row18 col2\" >0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ab5ae_level1_row19\" class=\"row_heading level1 row19\" >U4</th>\n",
       "      <td id=\"T_ab5ae_row19_col0\" class=\"data row19 col0\" >0.311</td>\n",
       "      <td id=\"T_ab5ae_row19_col1\" class=\"data row19 col1\" >1.000</td>\n",
       "      <td id=\"T_ab5ae_row19_col2\" class=\"data row19 col2\" >0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a763f100>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for participant_pair, d in results.items():\n",
    "    for simulated_user, metrics in d.items():\n",
    "        rows.append(\n",
    "            (\n",
    "                participant_pair,\n",
    "                simulated_user,\n",
    "                *(value for _, value in metrics.items()),\n",
    "            )\n",
    "        )\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Reference\", \"Simulated user pop.\", \"ROUGE-L\", \"Success rate\", \"Abs. diff. success rate\"],\n",
    ")\n",
    "summary.set_index([\"Reference\", \"Simulated user pop.\"], inplace=True)\n",
    "\n",
    "summary.style.format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jensen-Shannon divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsd_results = defaultdict(dict)\n",
    "\n",
    "for user_pop1, user_pop2 in product(USER_POPULATIONS.keys(), repeat=2):\n",
    "    if user_pop1 != user_pop2:\n",
    "        user_policy1 = USER_POPULATIONS[user_pop1].transition_probabilities\n",
    "        user_policy2 = USER_POPULATIONS[user_pop2].transition_probabilities\n",
    "        jsd = compute_jsd(user_policy1, user_policy2)\n",
    "        jsd_results[user_pop1][user_pop2] = jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4a19f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4a19f_level0_col0\" class=\"col_heading level0 col0\" >U1</th>\n",
       "      <th id=\"T_4a19f_level0_col1\" class=\"col_heading level0 col1\" >U2</th>\n",
       "      <th id=\"T_4a19f_level0_col2\" class=\"col_heading level0 col2\" >U3</th>\n",
       "      <th id=\"T_4a19f_level0_col3\" class=\"col_heading level0 col3\" >U4</th>\n",
       "      <th id=\"T_4a19f_level0_col4\" class=\"col_heading level0 col4\" >U5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4a19f_level0_row0\" class=\"row_heading level0 row0\" >U1</th>\n",
       "      <td id=\"T_4a19f_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_4a19f_row0_col1\" class=\"data row0 col1\" >0.211</td>\n",
       "      <td id=\"T_4a19f_row0_col2\" class=\"data row0 col2\" >0.357</td>\n",
       "      <td id=\"T_4a19f_row0_col3\" class=\"data row0 col3\" >0.543</td>\n",
       "      <td id=\"T_4a19f_row0_col4\" class=\"data row0 col4\" >0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a19f_level0_row1\" class=\"row_heading level0 row1\" >U2</th>\n",
       "      <td id=\"T_4a19f_row1_col0\" class=\"data row1 col0\" >0.211</td>\n",
       "      <td id=\"T_4a19f_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_4a19f_row1_col2\" class=\"data row1 col2\" >0.412</td>\n",
       "      <td id=\"T_4a19f_row1_col3\" class=\"data row1 col3\" >0.383</td>\n",
       "      <td id=\"T_4a19f_row1_col4\" class=\"data row1 col4\" >0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a19f_level0_row2\" class=\"row_heading level0 row2\" >U3</th>\n",
       "      <td id=\"T_4a19f_row2_col0\" class=\"data row2 col0\" >0.357</td>\n",
       "      <td id=\"T_4a19f_row2_col1\" class=\"data row2 col1\" >0.412</td>\n",
       "      <td id=\"T_4a19f_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_4a19f_row2_col3\" class=\"data row2 col3\" >0.330</td>\n",
       "      <td id=\"T_4a19f_row2_col4\" class=\"data row2 col4\" >0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a19f_level0_row3\" class=\"row_heading level0 row3\" >U4</th>\n",
       "      <td id=\"T_4a19f_row3_col0\" class=\"data row3 col0\" >0.543</td>\n",
       "      <td id=\"T_4a19f_row3_col1\" class=\"data row3 col1\" >0.383</td>\n",
       "      <td id=\"T_4a19f_row3_col2\" class=\"data row3 col2\" >0.330</td>\n",
       "      <td id=\"T_4a19f_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_4a19f_row3_col4\" class=\"data row3 col4\" >0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a19f_level0_row4\" class=\"row_heading level0 row4\" >U5</th>\n",
       "      <td id=\"T_4a19f_row4_col0\" class=\"data row4 col0\" >0.498</td>\n",
       "      <td id=\"T_4a19f_row4_col1\" class=\"data row4 col1\" >0.494</td>\n",
       "      <td id=\"T_4a19f_row4_col2\" class=\"data row4 col2\" >0.520</td>\n",
       "      <td id=\"T_4a19f_row4_col3\" class=\"data row4 col3\" >0.554</td>\n",
       "      <td id=\"T_4a19f_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a77a11c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(jsd_results).sort_index().style.format(precision=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigir24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
